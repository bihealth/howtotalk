---
title: "How to talk to your bioinformatician?"
author: 
  - name: "January Weiner"
    orcid: 0000-0003-1438-7819
    affiliations:
     - ref: cubi
affiliations:
  - id: cubi
    name: Core Unit for Bioinformatics, BIH@Charité
    address: Charitéplatz 1, 
    postal-code: 10117 
    city: Berlin 
    country: Germany
title-slide-attributes:
  data-background-image: files/bih_bg_logo.png
format:
  revealjs:
    footer: "Core Unit for Bioinformatics, BIH@Charite"
    theme: cubi.scss
    logo: files/bih_logo_small.png
    transition: fade
    slide-number: "c/t"
    smaller: true
    navigation-mode: linear
    self-contained: true
comments:
  hypothesis: true
knitr:
  opts_chunk:
    dev: "svg"
---


## Who am I to tell you things?

## Bioinformatics, statistics, computational biology

## Things bioinformaticians care about

 * The biological question
 * Statistics
 * Experimental design
 * Reproducibility
 * File formats

# Statistics

## Statistics matters

![](images/statistics.png)

## What is a p-value?

$H_0$: The null hypothesis, no effect

$H_1$: The alternative hypothesis, there is an effect

We run a test, we get a p-value. What is it?

 * Probability that $H_0$ is true, given the data
 * Probability that $H_1$ is wrong, given the data
 * Probability that the data is random

 . . .

 * **Probability of observing the data, given $H_0$ is true**

::: {.notes}
None of that is true
:::

## Our intuition is bayesian, not frequentist

::: {.fragment}

| **Frequentist Statistics**    | **Bayesian Statistics**     |
|-------------------------------|-----------------------------|
| ![](images/classicalgiants.png)| ![](images/thomas-bayes.png)      |
| 1. Probability is defined as the long-run frequency of events | 1. Probability represents a degree of belief or certainty about an event |
| 2. Parameters (like the "true value") are fixed but unknown quantities. | 2. Parameters are treated as random variables with their own probability distributions. |
| 3. Asking about the probability of a hypothesis does not make sense | 3. Asking about the probability of a hypothesis is the main goal |

:::

## Going beyond the p-value

  * Confidence intervals
  * Effect sizes
  * Power analysis

## Why is that important?

P-values are the *language* of science, whether we like them (we don't) or
not.

 * Use effect sizes *always*
 * Never rely on p-values alone

::: {.callout-tip}
You have to understand p-values and their limits to talk to other
scientists!
:::

::: {.aside}
Wasserstein RL, Lazar NA. The ASA statement on p-values: context, process, and purpose. The American Statistician. 2016 Apr 2;70(2):129-33.
:::


# Experimental design

## How many samples are sufficient?

:::: {.columns}
::: {.column width="45%"}

 * Depends on the question
 * Depends on the technology
 * Depends on the variability

:::
::: {.column width="10%"}
:::
::: {.column width="45%"}

![](images/pregnant.jpg)

:::
::::

## How many samples are sufficient?

Say, we want to compare two groups with a standard $t-test$, nothing fancy.
Our ability to detect the differences (the statistical *power*) depends on
the sample size and the effect size[^cohen].


```{r echo=FALSE}
#| label: effect_sizes
#| fig-width: 9
#| fig-height: 4
# plot four effect sizes as boxplots
library(tidyverse)
library(ggplot2)
library(ggbeeswarm)

n_samp <- c(3, 4, 5, 7, 10, 15, 25)
d <- c(Medium=0.5, Large=.8, "Very large"=1.2, Huge=2.0)
n_samples <- 100

df <- imap_dfr(d, ~ {
  d_val <- .x
  size <- .y

  x <- rnorm(n_samples, mean = 0, sd = 1)
  y <- rnorm(n_samples, mean = d_val, sd = 1)

  data.frame(value = c(x, y), group = rep(c("A", "B"), each = n_samples), d = d_val, size=size)
}) %>%
  mutate(size = paste0(size, " (d=", d, ")")) %>%
  mutate(size = factor(size, levels=c("Medium (d=0.5)", "Large (d=0.8)", "Very large (d=1.2)", "Huge (d=2)")))


ggplot(df, aes(x = group, y = value, fill = group)) +
  geom_boxplot(outlier.shape = NA) +
  geom_beeswarm(alpha=.25, corral.width=1.5) +
  facet_wrap(~ size, ncol=4) +
  labs(x = "Group", y = "Value", fill = "Group") +
  theme(legend.position = "none")
```





[^cohen]: Here we use Cohen's $d$

## How many samples are sufficient?

The $y$ axis on this plot shows how the power of the test – meaning how
often, assuming that the groups really differ by $d$ on average, you will
be able to detect the difference using a t-test.

```{r echo=FALSE,cache=TRUE}
#| label: power
# we could use pwr package here, but simulation is more explicit

# parameters
n <- 1000

# simulation
power <- map_dfr(n_samp, ~ {
  n_samples <- .x
  map_dfr(d, ~ {
    d_val <- .x
    pwr <- map_dbl(1:n, ~ {
      x <- rnorm(n_samples, mean = 0, sd = 1)
      y <- rnorm(n_samples, mean = d_val, sd = 1)
      t.test(x, y)$p.value
    }) < 0.05
    data.frame(n_samples = n_samples, d = d_val, power = mean(pwr))
  })
  
}) %>%
  mutate(study = "Simple t-test")
```

```{r}
#| label: power_plot_simple
#| fig-width: 9
#| fig-height: 4

ggplot(power, aes(x = n_samples, y = power, color = factor(d))) +
  geom_point() +
  geom_line() +
  scale_color_discrete(name = "Effect size") +
  scale_x_log10() +
  labs(x = "Number of samples", y = "Power")

```


## How many samples are sufficient?

What about the following setup:

 * We have 2 strains (WT and KO)
 * We have treatment + control
 * We want to know whether the treatment has a different effect on the KO
   strain than on the WT strain

This is a 2x2 design, and we need to consider the interaction term.

## How many samples are sufficient?

```{r echo=FALSE,cache=TRUE}
#| label: power_int
# we could use pwr package here, but simulation is more explicit
library(broom)

# parameters
n <- 1000

# simulation
power_int <- map_dfr(n_samp, ~ {
  n_samples <- .x
  map_dfr(d, ~ {
    d_val <- .x
    pwr <- map_dbl(1:n, ~ {
      x <- rnorm(n_samples, mean = 0, sd = 1)
      y <- rnorm(n_samples, mean = 0, sd = 1)
      z <- rnorm(n_samples, mean = 0, sd = 1)
      w <- rnorm(n_samples, mean = 1 * d_val, sd = 1)
      df <- data.frame(x=c(x, y, z, w), 
                       strain=rep(c("WT", "KO"), each=2 * n_samples),
                       group=rep(c("Control", "Treatment"), each=n_samples))
      mod <- lm(x ~ strain * group, data = df)
      anova(mod)$`Pr(>F)`[3]
    }) < 0.05
    data.frame(n_samples = n_samples, d = d_val, power = mean(pwr))
  })
}) %>% 
  mutate(study = "Interaction")
```



```{r echo=FALSE}
#| label: power_plot

power_tot <- rbind(power, power_int) %>%
  mutate(study = factor(study, levels=c("Simple t-test", "Interaction")))

ggplot(power_tot, aes(x = n_samples, y = power, color = factor(d))) +
  geom_point() +
  geom_line() +
  scale_color_discrete(name = "Effect size") +
  labs(x = "Number of samples", y = "Power") +
  facet_wrap(~ study)
```

## How many samples are sufficient?

That is not even the worse thing.

Simple calculations show that assuming

 * your power is 80% (really great!)
 * $p-value$ cutoff is $0.05$
 * 90% of the $H_0$ are true (i.e., 10% of the time the differences are
   real)

then 36% of your "significant" results **are false positives**[^more]!

(Plus, you failed to detect 20% of the real differences)

[^more]: I can walk you through a very simple demonstration later if you
care.

::: {.aside}
Colquhoun D. An investigation of the false discovery rate and the misinterpretation of p-values. Royal Society open science. 2014 Nov 19;1(3):140216.
:::
 
## The bottom line

### Talk to your bioinformatician early!

# Reproducibility

## Tale of two papers

![](images/pnas_1.png)


## Tale of two papers

![](images/pnas_res_1.png)


## Tale of two papers

![](images/pnas_1.png)

. . .

![](images/pnas_2.png)

## Tale of two papers

![](images/pnas_1.png)


![](images/pnas_2_red.png)

## Tale of two papers

![](images/pnas_res_2.png)

::: {.notes}
Key difference - second paper specifically focused on genes that were
regulated in either mouse model or human data, and asked whether they are
similar or not
:::

## Lessons learned

 * *A lot* depends on how you analyze your data

 . . .

 * This in turn depends on the questions you ask

 . . .

 * The average "Methods" section is not sufficient for reproducible
   science!

## Reproducible workflows with Rmarkdown

```{mermaid}
flowchart LR
    A(Program + Text) -->|knitr| B(Text with\nanalysis results)
    B --> C[LaTeX]
    C --> CC[PDF]
    B --> D[Word]
    B --> E[HTML]
    B --> F[Presentation]
    B --> G[Book]
```

*This can be Rmarkdown, Quarto, Jupyter... the goal is that your code and
your text are in one place, and the results of your calculations are
entered automatically into the text.*

## Reproducible workflows with Rmarkdown


```{r include=FALSE}
p <- 0.05
```

In systems such ar R markdown, you can put directly your
analysis results in your text. For example, when I write that the
$p$-value is equal to `r p`, I am writing this:

```markdown
In systems such ar R markdown, you can put directly your
analysis results in your text. For example, when I write that the
$p$-value is equal to `​r p`, I am writing this:
```

The $p$-value above is not entered manually (as 0.05), but is the result of
a statistical computation. If the data changes, if your analysis changes,
the $p$-value above will automatically change as well.


# File formats and data management

## How we work

```{mermaid}
flowchart LR
    A(Excel) --> B(Data import)
    AA(CSV, TSV) --> B(Data import)
    AAA(fastq, ...) --> B(Data import)
    B --> C[Data\ncleanup]
    C --> D[Long term storage]
    C --> E[Analysis]
    E --> D
    E --> F(Figures)
    E --> G(Manuscript\nfragments)
    E --> H(Tables\nExcel files)
    F --> I[You]
    G --> I
    H --> I
    I --> E
```

In the diagram above, two things take usually the most hands-on time:

 * Data cleanup
 * Fine-tuning the analysis results

## Identifiers


::: {.notes}
 * Identifiers are unique
 * Identifiers are stable
 * Identifiers are machine-readable
:::

## Excel and gene names

:::: {.columns}
::: {.column width="60%"}

 * Excel converts some words to dates automatically
 * Gene names like `MARCH1` are converted to dates
 * In most cases[^cases], you can't switch off this behavior

[^cases]: You can change the data type for a column to "text" before
pasting data in, but this is just a workaround. In Office 365 it is
possible to switch off this behavior.

:::
::: {.column width="5%"}
:::

::: {.column width="35%"}

:::
::::

## Excel and gene names

::: {.r-stack}
![](images/excel_paper_1.png){.fragment .absolute top=90 left=10 width=80%}

![](images/excel_hgnc.png){.fragment .absolute top=120 left=50 width=80%}

![](images/excel_paper_2.png){.fragment .absolute top=220 left=90 width=80%}
:::


::: {.aside style="font-size: 0.8em; color:red;"}
::: {style="font-size: 0.5em;"}
Ziemann, Mark, Yotam Eren, and Assam El-Osta. "Gene name errors are widespread in the scientific literature." Genome biology 17 (2016): 1-3; 
Abeysooriya M, Soria M, Kasu MS, Ziemann M. Gene name errors: Lessons not learned. PLoS Computational Biology. 2021 Jul 30;17(7):e1008984.
:::
:::

::: {.notes}
2016 paper: 20% of papers have Excel gene name errors
2021 paper: it is 30% now. Excel now learned mulitple languages
:::

## How (not to) work with Excel

Three reasons why you should follow these rules:

 1. Fewer chances of errors
 1. You bioinformaticians will love you
 2. The analysis will be done much faster





## How (not to) work with Excel

:::: {.columns}
::: {.column width="60%"}

### Avoid manually change Excel files

 * Manual changes cannot be tracked automatically
 * You have to record every change you make
 * Otherwise, this is not reproducible science!

:::

::: {.column width="5%"}
:::

::: {.column width="35%"}


:::
::::





## How (not to) work with Excel

:::: {.columns}
::: {.column width="60%"}

### Never use formatting for data

Never encode information as formatting, always use explicit columns

Color / font size / font style cannot be read automatically 

:::
::: {.column width="5%"}
:::
::: {.column width="35%"}

![](images/excel_1.png)

:::
::::




## How (not to) work with Excel

:::: {.columns}
::: {.column width="60%"}

### Don't combine values and comments

Make a separate column for comments

Otherwise the values might be lost[^lost]

[^lost]: If the bioinformatician in charge is sloppy

:::
::: {.column width="5%"}
:::
::: {.column width="35%"}

![](images/excel_comments.png)

:::
::::




## How (not to) work with Excel

:::: {.columns}
::: {.column width="60%"}

### Don't put meta-information into column names

Make a separate excel sheet for column meta information

:::
::: {.column width="5%"}
:::
::: {.column width="35%"}

![](images/excel_colnames.png)

:::
::::




## How (not to) work with Excel

(for your reference)

 * Avoid manually changing Excel files
 * Never use formatting for data
 * Don't combine values and comments
 * Don't put meta-information into column names
 * One sheet = one table
 * Header = one line
 * Do not use merged cells
 * Use consistent file names
 * Avoid spaces in file and column names (use underscores)


# Some more tips and summaries

## 

:::: {.columns}
::: {.column width="50%"}

### Things we don't like

 * Cleaning up data
 * Data dredging
 * P-hacking
 * Post-hoc hypotheses
 * Excel
 * Manual changes like changing fonts in figures
 * Non-reproducible science

:::
::: {.column width="50%"}

### Things we love

 * Clear questions
 * A priori hypotheses
 * Challenging statistics
 * Creating new tools
 * R and Rmarkdown, or
 * Python and Jupyter
 * Reproducible workflows
 * Well organized data

:::
::::

## Things that you should probably learn

 * Learn how to code (preferably R or Python)
 * Learn reproducible workflows with Rmarkdown or Jupyter



## Thank you {.inverse background-color="#70ADC1"}

:::: {.columns}

::: {.column width="40%"}
You can find this presentation along its source code 
at [https://github.com/bihealth/howtotalk](https://github.com/bihealth/howtotalk)

 
:::

::: {.column width="40%"}
:::

::: {.column width="20%"}

```{r}
#| fig-width: 5
#| fig-height: 5
library(qrcode)
plot(qr_code("https://github.com/bihealth/howtotalk"))
```



:::
::::

